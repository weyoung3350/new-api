#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
wanx2.1-t2i-turbo æ¨¡å‹æµ‹è¯•è„šæœ¬
æµ‹è¯•é˜¿é‡Œäº‘é€šä¹‰ä¸‡ç›¸å›¾åƒç”Ÿæˆæ¨¡å‹çš„APIæ¥å£
"""

import os
import json
import time
import requests
from typing import Dict, Any, Optional
from dataclasses import dataclass
import logging
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('wanx_test_results.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class APIConfig:
    """APIé…ç½®ç±»"""
    base_url: str = "http://localhost:3000"
    api_key: str = ""
    timeout: int = 60
    
    def __post_init__(self):
        if not self.api_key:
            # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
            self.api_key = os.getenv("NEW_API_KEY", "sk-test-key")
            if not self.api_key or self.api_key == "sk-test-key":
                logger.warning("è¯·è®¾ç½®NEW_API_KEYç¯å¢ƒå˜é‡æˆ–åœ¨ä»£ç ä¸­é…ç½®APIå¯†é’¥")

class WanxModelTester:
    """wanx2.1-t2i-turbo æ¨¡å‹æµ‹è¯•å™¨"""
    
    def __init__(self, config: APIConfig):
        self.config = config
        self.session = requests.Session()
        self.session.headers.update({
            'Authorization': f'Bearer {config.api_key}',
            'Content-Type': 'application/json',
            'User-Agent': 'wanx-model-tester/1.0'
        })
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir = Path("test_outputs")
        self.output_dir.mkdir(exist_ok=True)
    
    def test_model_availability(self) -> bool:
        """æµ‹è¯•æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        try:
            url = f"{self.config.base_url}/v1/models"
            response = self.session.get(url, timeout=self.config.timeout)
            
            if response.status_code == 200:
                models = response.json()
                model_names = [model['id'] for model in models.get('data', [])]
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«wanxç›¸å…³æ¨¡å‹
                wanx_models = [m for m in model_names if 'wanx' in m.lower()]
                
                logger.info(f"âœ… æ¨¡å‹åˆ—è¡¨è·å–æˆåŠŸï¼Œå…±å‘ç° {len(model_names)} ä¸ªæ¨¡å‹")
                if wanx_models:
                    logger.info(f"ğŸ¨ å‘ç°WANXç›¸å…³æ¨¡å‹: {wanx_models}")
                else:
                    logger.info("ğŸ“ æœªå‘ç°WANXç›¸å…³æ¨¡å‹ï¼Œå°†ä½¿ç”¨é€šç”¨å›¾åƒç”Ÿæˆæ¥å£")
                
                return True
            else:
                logger.error(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§å¤±è´¥: {str(e)}")
            return False
    
    def test_image_generation(self, prompt: str, model: str = "wanx2.1-t2i-turbo") -> Dict[str, Any]:
        """æµ‹è¯•å›¾åƒç”ŸæˆåŠŸèƒ½"""
        logger.info(f"ğŸ¨ å¼€å§‹æµ‹è¯•å›¾åƒç”Ÿæˆ - æ¨¡å‹: {model}")
        logger.info(f"ğŸ“ æç¤ºè¯: {prompt}")
        
        try:
            url = f"{self.config.base_url}/v1/images/generations"
            
            payload = {
                "model": model,
                "prompt": prompt,
                "n": 1,
                "size": "1024x1024",
                "quality": "standard",
                "response_format": "url"
            }
            
            start_time = time.time()
            response = self.session.post(
                url, 
                json=payload, 
                timeout=self.config.timeout
            )
            end_time = time.time()
            
            response_time = end_time - start_time
            
            result = {
                "success": False,
                "response_time": response_time,
                "status_code": response.status_code,
                "model": model,
                "prompt": prompt
            }
            
            if response.status_code == 200:
                data = response.json()
                result.update({
                    "success": True,
                    "response_data": data,
                    "image_urls": [img.get('url') for img in data.get('data', [])],
                    "revised_prompt": data.get('data', [{}])[0].get('revised_prompt', '')
                })
                
                logger.info(f"âœ… å›¾åƒç”ŸæˆæˆåŠŸï¼")
                logger.info(f"â±ï¸  å“åº”æ—¶é—´: {response_time:.2f}ç§’")
                logger.info(f"ğŸ–¼ï¸  ç”Ÿæˆå›¾åƒæ•°é‡: {len(result['image_urls'])}")
                
                if result['revised_prompt']:
                    logger.info(f"ğŸ“ ä¼˜åŒ–åæç¤ºè¯: {result['revised_prompt']}")
                
                # ä¿å­˜ç»“æœ
                self._save_test_result(result)
                
            else:
                result.update({
                    "error": response.text,
                    "headers": dict(response.headers)
                })
                logger.error(f"âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {response.status_code}")
                logger.error(f"ğŸ“„ é”™è¯¯ä¿¡æ¯: {response.text}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ å›¾åƒç”Ÿæˆæµ‹è¯•å¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "model": model,
                "prompt": prompt
            }
    
    def test_multiple_prompts(self, prompts: list, model: str = "wanx2.1-t2i-turbo") -> Dict[str, Any]:
        """æµ‹è¯•å¤šä¸ªæç¤ºè¯"""
        logger.info(f"ğŸ”„ å¼€å§‹æ‰¹é‡æµ‹è¯• - å…± {len(prompts)} ä¸ªæç¤ºè¯")
        
        results = []
        successful_tests = 0
        
        for i, prompt in enumerate(prompts, 1):
            logger.info(f"\n--- æµ‹è¯• {i}/{len(prompts)} ---")
            result = self.test_image_generation(prompt, model)
            results.append(result)
            
            if result.get('success'):
                successful_tests += 1
            
            # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            time.sleep(1)
        
        summary = {
            "total_tests": len(prompts),
            "successful_tests": successful_tests,
            "failed_tests": len(prompts) - successful_tests,
            "success_rate": (successful_tests / len(prompts)) * 100,
            "results": results
        }
        
        logger.info(f"\nğŸ“Š æ‰¹é‡æµ‹è¯•å®Œæˆ:")
        logger.info(f"âœ… æˆåŠŸ: {successful_tests}/{len(prompts)} ({summary['success_rate']:.1f}%)")
        logger.info(f"âŒ å¤±è´¥: {summary['failed_tests']}/{len(prompts)}")
        
        return summary
    
    def _save_test_result(self, result: Dict[str, Any]):
        """ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"wanx_test_{timestamp}.json"
        filepath = self.output_dir / filename
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜: {filepath}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æµ‹è¯•ç»“æœå¤±è´¥: {str(e)}")
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹ wanx2.1-t2i-turbo æ¨¡å‹ç»¼åˆæµ‹è¯•")
        logger.info("=" * 60)
        
        # 1. æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§
        logger.info("1ï¸âƒ£ æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§...")
        if not self.test_model_availability():
            return {"success": False, "error": "æ¨¡å‹ä¸å¯ç”¨"}
        
        # 2. å‡†å¤‡æµ‹è¯•æç¤ºè¯
        test_prompts = [
            "ä¸€åªå¯çˆ±çš„å°çŒ«å’ªååœ¨é˜³å…‰ä¸‹çš„èŠ±å›­é‡Œ",
            "ç°ä»£åŸå¸‚å¤œæ™¯ï¼Œéœ“è™¹ç¯é—ªçƒï¼Œé«˜æ¥¼å¤§å¦æ—ç«‹",
            "å¤ä»£ä¸­å›½å±±æ°´ç”»é£æ ¼ï¼Œå±±å³¦å å¶‚ï¼Œäº‘é›¾ç¼­ç»•",
            "ç§‘å¹»æœªæ¥ä¸–ç•Œï¼Œé£è¡Œæ±½è½¦åœ¨ç©ºä¸­ç©¿æ¢­",
            "æ¸©é¦¨çš„å’–å•¡å…å†…éƒ¨ï¼Œæš–é»„è‰²ç¯å…‰ï¼Œä¹¦æ¶å’Œæ¤ç‰©"
        ]
        
        # 3. æ‰§è¡Œå›¾åƒç”Ÿæˆæµ‹è¯•
        logger.info(f"\n2ï¸âƒ£ å¼€å§‹å›¾åƒç”Ÿæˆæµ‹è¯•...")
        test_results = self.test_multiple_prompts(test_prompts)
        
        # 4. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        final_report = {
            "test_type": "wanx2.1-t2i-turbo æ¨¡å‹ç»¼åˆæµ‹è¯•",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "config": {
                "base_url": self.config.base_url,
                "model": "wanx2.1-t2i-turbo",
                "timeout": self.config.timeout
            },
            "results": test_results,
            "summary": {
                "total_prompts": len(test_prompts),
                "success_rate": test_results.get('success_rate', 0),
                "average_response_time": self._calculate_average_response_time(test_results.get('results', []))
            }
        }
        
        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        self._save_final_report(final_report)
        
        return final_report
    
    def _calculate_average_response_time(self, results: list) -> float:
        """è®¡ç®—å¹³å‡å“åº”æ—¶é—´"""
        if not results:
            return 0.0
        
        successful_results = [r for r in results if r.get('success') and 'response_time' in r]
        if not successful_results:
            return 0.0
        
        total_time = sum(r['response_time'] for r in successful_results)
        return total_time / len(successful_results)
    
    def _save_final_report(self, report: Dict[str, Any]):
        """ä¿å­˜æœ€ç»ˆæµ‹è¯•æŠ¥å‘Š"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"wanx_final_report_{timestamp}.json"
        filepath = self.output_dir / filename
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“‹ æœ€ç»ˆæµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {filepath}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ wanx2.1-t2i-turbo æ¨¡å‹æµ‹è¯•è„šæœ¬")
    print("æµ‹è¯•é˜¿é‡Œäº‘é€šä¹‰ä¸‡ç›¸å›¾åƒç”Ÿæˆæ¨¡å‹")
    print("-" * 60)
    
    # é…ç½®API
    config = APIConfig(
        base_url="http://localhost:3000",
        api_key=os.getenv("NEW_API_KEY", "sk-test-key"),
        timeout=60
    )
    
    if not config.api_key or config.api_key == "sk-test-key":
        print("âš ï¸  è¯·è®¾ç½®NEW_API_KEYç¯å¢ƒå˜é‡æˆ–åœ¨ä»£ç ä¸­é…ç½®APIå¯†é’¥")
        print("   export NEW_API_KEY='your-api-key'")
        return
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = WanxModelTester(config)
    
    try:
        # è¿è¡Œç»¼åˆæµ‹è¯•
        report = tester.run_comprehensive_test()
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦:")
        print(f"âœ… æˆåŠŸç‡: {report['summary']['success_rate']:.1f}%")
        print(f"â±ï¸  å¹³å‡å“åº”æ—¶é—´: {report['summary']['average_response_time']:.2f}ç§’")
        print(f"ğŸ“ æ€»æµ‹è¯•æ•°: {report['summary']['total_prompts']}")
        print("=" * 60)
        
        if report['results']['success_rate'] > 0:
            print("ğŸ‰ æµ‹è¯•å®Œæˆï¼éƒ¨åˆ†æˆ–å…¨éƒ¨æµ‹è¯•æˆåŠŸ")
        else:
            print("âŒ æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main() 